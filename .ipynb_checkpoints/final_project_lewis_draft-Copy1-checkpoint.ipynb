{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2646a34e-a634-47ac-9fe7-73bf40ece8ae",
   "metadata": {},
   "source": [
    "# HW2/Final Project Template: Dataset Overview and Use Case Examples\n",
    "## EDS 220, Fall 2022\n",
    "\n",
    "The following is a template you can use for constructing your draft Jupyter notebooks demonstrating the features and use case examples for your chosen environmental datasets. I've included sections addressing the major themes that should be included, but there is also room for customization as well. \n",
    "\n",
    "Many of the resources provided are adapted from this template guide to notebook creation built for the \"EarthCube\" project:\n",
    "https://github.com/earthcube/NotebookTemplates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a405bf-2d38-4175-a931-f52905e11211",
   "metadata": {},
   "source": [
    "## An Analysis of Global Flood Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc47afd0-adb0-4d5b-8903-992b7904322e",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Amrit Sandhu, UC Santa Barbara (aksandhu@ucsb.edu) <br>\n",
    "- Elise Gonzales, UC Santa Barbara (efgonzales@ucsb.edu) <br>\n",
    "- Lewis White, UC Santa Barbara (lewiswhite@ucsb.edu) <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c2013-fef1-44ac-bb00-3215807cacac",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "Include a summary of the various sections included in your notebook, so that users can easily skip to a section of interest. It's also good to include hyperlinks to the different sections, so that clicking on the heading sends one to that section directly. Examples are below; see also this handy guide to adding hyperlinks to Jupyter notebooks:\n",
    "https://medium.illumidesk.com/jupyter-notebook-little-known-tricks-b0866a558017\n",
    "\n",
    "The major sections you'll need for HW2 - and your group project - are shown below:\n",
    "\n",
    "[1. Purpose](#purpose)\n",
    "\n",
    "[2. Dataset Description](#overview)\n",
    "\n",
    "[3. Data I/O](#io)\n",
    "\n",
    "[4. Metadata Display and Basic Visualization](#display)\n",
    "\n",
    "[5. Use Case Examples](#usecases)\n",
    "\n",
    "[6. Create Binder Environment](#binder)\n",
    "\n",
    "[7. References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52c6e3-3584-48be-b500-21578b61bd72",
   "metadata": {},
   "source": [
    "<a id='purpose'></a> \n",
    "### Notebook Purpose\n",
    "\n",
    "State the overall purpose of the notebook. Again, this may seem obvious for this particular case, but can come in handy if you're using the notebook later on!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429260a-2c30-44da-a5af-e100a440056a",
   "metadata": {},
   "source": [
    "<a id='overview'></a> \n",
    "### Dataset Description\n",
    "\n",
    "This portion of the notebook should contain a summary description of your chosen environmental dataset. In a few paragraphs, discuss:\n",
    "- The creators of the dataset: NASA/NOAA/other government agency? Nonprofit? etc.\n",
    "- Major characteristics of the dataset: global coverage? Spatial resolution? Temporal resolution? Creation date? \n",
    "- The file format(s) used to store the data: netCDF? CSV? Other?\n",
    "- The source/archive you will be using to retrieve the data: Google Earth Engine? Agency data portal? Other API?\n",
    "- Any known issues with data quality that might be expected to impact the results\n",
    "\n",
    "Include links to any external resources needed to access the data here, including either the location of files stored on an external server you've set up or the access URL for a pre-existing repository. You can also include any example images you find useful for motivating the choice of dataset (optional).\n",
    "\n",
    "**Here and throughout the notebook:** use a mix of markdown cells and code blocks to demonstrate your code. Markdown cells should be used to describe the purpose of the code blocks which follow them, but _do not replace_ comments within the code block! Make sure to include comments in the code as well illustrating the specific function of the various lines of code. Your later self - and other users - will thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d5cb75-cb54-4708-8b88-459cae2ca17d",
   "metadata": {},
   "source": [
    "<a id='io'></a> \n",
    "### Dataset Input/Output \n",
    "\n",
    "Next, provide code to read in the data necessary for your analysis. This should be in the following order:\n",
    "\n",
    "1) Import all necessary packages (matplotlib, numpy, etc)\n",
    "\n",
    "2) Set any parameters that will be needed during subsequent portions of the notebook. Typical examples of parameters include:\n",
    "- names of any directories where data are stored\n",
    "- ranges of years over which data are valid\n",
    "- any thresholds or latitude/longitude ranges to be used later (e.g. dimensions of NINO3.4 region, threshold SSTA values for El Nino, etc.)\n",
    "\n",
    "3) Read in the data! If the data files are very large, you may want to consider subsetting the portion of files to be read in (see examples of this during notebooks provided in Weeks 7 and 8).\n",
    "\n",
    "Here is a good rule of thumb: It's good to aim for a relatively short amount of time needed to read in the data, since otherwise we'll be sitting around waiting for things to load for a long time. A  minute or two for data I/O is probably the max you'll want to target!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6893909-5c06-4dcd-82b0-1f76a29dc61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import ee\n",
    "import geemap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd06fae9-6ac8-4b34-9696-e0bab532d81b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#authenticate and initialize google earth engine API\n",
    "\n",
    "#ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75a0ee95-ad32-4b2a-80a3-609c6b735392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ee.ImageCollection({\n",
      "  \"functionInvocationValue\": {\n",
      "    \"functionName\": \"ImageCollection.load\",\n",
      "    \"arguments\": {\n",
      "      \"id\": {\n",
      "        \"constantValue\": \"GLOBAL_FLOOD_DB/MODIS_EVENTS/V1\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#retrieving the data from Earth Engine API. \n",
    "\n",
    "#gfd stands for global flood data\n",
    "gfd = ee.ImageCollection(\"GLOBAL_FLOOD_DB/MODIS_EVENTS/V1\") \n",
    "\n",
    "#checking out our data\n",
    "#print(gfd)\n",
    "\n",
    "#gfd.getInfo() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d079fad-8fc8-4301-8e98-3a3fd6e519d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553bbdd43bf049e5bd4346a6a659b826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[40, -100], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_out_t…"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Map all floods to generate the satellite-observed historical flood plain.\n",
    "\n",
    "#initialize map, centered around kansas ~ the geographic centroid of the USA\n",
    "Map = geemap.Map(center=[-100, 40], zoom=4)\n",
    "\n",
    "#using a satellite true color map\n",
    "Map.setOptions('SATELLITE')\n",
    "\n",
    "#set center of the map\n",
    "Map.setCenter(-100, 40, 4)\n",
    "\n",
    "#sum all of the flood events to get the entire historical flood plain\n",
    "gfdFloodedSum = gfd.select('flooded').sum();\n",
    "\n",
    "#create a palette for the raster data. Here, darker blue represents longer flood duration. \n",
    "durationPalette = ['C3EFFE', '1341E8', '051CB0', '001133', '#00020a']\n",
    "\n",
    "#add the flood data layer to our previously initialized map\n",
    "Map.addLayer(\n",
    "  gfdFloodedSum.selfMask(),\n",
    "  {'min': 0, 'max': 10, 'palette': durationPalette})\n",
    "\n",
    "#plot the map\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c20bbdc-589e-468f-972f-61a5c9e592c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553bbdd43bf049e5bd4346a6a659b826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=27572.0, center=[28.8831596093235, -91.29364013671875], controls=(ZoomControl(options=['position', …"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Overlay permanent water to distinguish flood water from permanent water. \n",
    "\n",
    "#filters to just perm water. gte(1) means \n",
    "perm_water = gfd.select('jrc_perm_water').sum()\n",
    "\n",
    "#adding the perm water later (a light cyan color) to the map\n",
    "Map.addLayer(\n",
    "  perm_water.selfMask(),\n",
    "  {'min': 0, 'max': 1, 'palette': 'C3EFFE'},\n",
    "  'JRC Permanent Water');\n",
    "\n",
    "#plotting the map\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e2ded60-dd78-42db-af65-4b7130f28dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82e0785132944b38b1395303c502ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[29.4064, -90.2922], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'z…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#An individual flood event - flooding due to Hurricane Isaac in the USA.\n",
    "\n",
    "hurricaneIsaacDartmouthId = 3977;\n",
    "\n",
    "hurricaneIsaacUsa = ee.Image(gfd.filterMetadata('id', 'equals', hurricaneIsaacDartmouthId).first());\n",
    "\n",
    "Map = geemap.Map(center=[-90.2922, 29.4064], zoom=9)\n",
    "\n",
    "Map.setOptions('SATELLITE')\n",
    "\n",
    "Map.setCenter(-90.2922, 29.4064, 8)\n",
    "\n",
    "\n",
    "Map.addLayer(hurricaneIsaacUsa.select('flooded').selfMask(),\n",
    "             {'min': 0, 'max': 1, 'palette': ['00FFFF', '0000FF']},\n",
    "             'Hurricane Isaac - Inundation Extent')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd53572-34bf-4f85-bef5-c583f192c5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82e0785132944b38b1395303c502ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=27463.0, center=[29.4064, -90.2922], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zo…"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The duration (number of days a flood event lasted).\n",
    "durationPalette = ['C3EFFE', '1341E8', '051CB0', '001133', '#00020a'] #darker blue is longer d\n",
    "\n",
    "Map.addLayer(\n",
    "  hurricaneIsaacUsa.select('duration').selfMask(),\n",
    "  {'min': 0, 'max': 4, 'palette': durationPalette},\n",
    "  'Hurricane Isaac - Duration');\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a369dd5-196c-475a-ae40-5f1d4b0c72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gfd.propertyNames().getInfo()\n",
    " \n",
    "#gfd.get('date_range').getInfo()\n",
    "\n",
    "#hurricaneIsaacUsa.propertyNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a635e824-0664-475f-9aef-98686723e63b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'ImageCollection',\n",
       " 'bands': [],\n",
       " 'id': 'GLOBAL_FLOOD_DB/MODIS_EVENTS/V1',\n",
       " 'version': 1641990150503727,\n",
       " 'properties': {'date_range': [950745600000, 1544400000000],\n",
       "  'period': 0,\n",
       "  'type_name': 'ImageCollection',\n",
       "  'max_mirrored_version': 1627592385154748,\n",
       "  'keywords': ['c2s',\n",
       "   'cloudtostreet',\n",
       "   'dartmouth',\n",
       "   'dfo',\n",
       "   'flood',\n",
       "   'gfd',\n",
       "   'inundation',\n",
       "   'surface',\n",
       "   'water'],\n",
       "  'thumb': 'https://mw1.google.com/ges/dd/images/GLOBAL_FLOOD_DB_MODIS_EVENTS_V1_0_thumb.png',\n",
       "  'description': '<p>The Global Flood Database contains maps of the extent and\\ntemporal distribution of 913 flood events occurring between 2000-2018. For more\\ninformation, see\\n<a href=\"https://doi.org/10.1038/s41586-021-03695-w\">the associated journal article</a>.</p><p>Flood events were collected from\\nthe <a href=\"https://floodobservatory.colorado.edu/\">Dartmouth Flood Observatory</a>\\nand used to collect MODIS imagery. The selected\\n913 events are those that were successfully mapped (passed quality control as\\nhaving significant inundation beyond permanent water) using 12,719 scenes from\\nTerra and Aqua MODIS sensors. Each pixel was classified as water or non-water\\nat 250-meter resolution during the full date range of each flood event and\\nsubsequent data products were generated including maximum flood extent\\n(&quot;flooded&quot; band) and the duration of inundation in days (&quot;duration&quot; band).\\nWater and non-water classifications during a flood event include permanent\\nwater (here resampling the 30-meter\\n<a href=\"https://global-surface-water.appspot.com/\">JRC Global Surface Water dataset</a>\\nrepresenting permanent water to 250-meter resolution), which can be\\nmasked out to isolate flood water using the &quot;jrc_perm_water&quot; band.\\nExtra data quality\\nbands were added representing cloud conditions during the flood event (e.g.,\\n&quot;clear_views&quot; representing the number of clear days the flood was observed\\nbetween its start and end dates and &quot;clear_perc&quot; representing the percentage of\\nclear day observation of the total event duration in days).</p><p>Each image in the ImageCollection represents the map of an individual flood.\\nThe collection can be filtered\\nby date, country, or Dartmouth Flood Observatory original ID.</p><p><b>Provider: <a href=\"http://global-flood-database.cloudtostreet.info/\">Cloud to Street (C2S) / Dartmouth Flood Observatory (DFO)</a></b><br><p><b>Resolution</b><br>30 meters\\n</p><p><b>Bands</b><table class=\"eecat\"><tr><th scope=\"col\">Name</th><th scope=\"col\">Description</th></tr><tr><td>flooded</td><td><p>Maximum extent of flood water during an event.</p><ul><li>1 - area of surface water</li><li>0 - no water</li></ul></td></tr><tr><td>flood_duration</td><td><p>Duration of surface water during an event in days. Pixel values indicate\\nthe number of composite days a pixel’s area was considered water during an\\nevent. 3-day MODIS composites were used.</p></td></tr><tr><td>clear_views</td><td><p>Number of cloud-free observations in days between the start and end day\\nof each event. Cloud coverage is determined by the MODIS Quality\\nAssurance band (&#39;state_1km&#39;).</p></td></tr><tr><td>clear_perc</td><td><p>Percentage of clear view observations during a given flood event. This is\\nequivalent to the &#39;clear_views&#39; band but normalized to the number of MODIS\\nimages per flood event.  Cloud coverage is determined by the MODIS\\nQuality Assurance band (&#39;state_1km&#39;).</p></td></tr><tr><td>jrc_perm_water</td><td><p>Permanent water determined by the JRC Global Surface Water dataset using the\\n&#39;transition&#39; band.  Resolution is maintained as the original 30-meter\\nresolution of the JRC dataset.</p><ul><li>1 - permanent water</li><li>0 - non-water.</li></ul></td></tr></table><p><b>Image Properties</b><table class=\"eecat\"><tr><th scope=\"col\">Name</th><th scope=\"col\">Type</th><th scope=\"col\">Description</th></tr><tr><td>id</td><td>INT</td><td><p>Unique catalog ID of flood event that aligns with the Dartmouth Flood\\nObservatory (DFO).</p></td></tr><tr><td>cc</td><td>STRING</td><td><p>Three-letter ISO country codes (in a list) for countries for which\\nflood water was detected in watersheds intersecting the DFO event polygon.</p></td></tr><tr><td>countries</td><td>STRING</td><td><p>Country names (in a list) for countries for which flood water was\\ndetected in watersheds intersecting the DFO event polygon.</p></td></tr><tr><td>dfo_centroid_x</td><td>DOUBLE</td><td><p>Centroid longitude of DFO polygon estimating the location of a flood\\nevent (DFO database).</p></td></tr><tr><td>dfo_centroid_y</td><td>DOUBLE</td><td><p>Centroid latitude of DFO polygon estimating the location of a flood\\nevent (DFO database).</p></td></tr><tr><td>dfo_country</td><td>STRING</td><td><p>Primary country of flooding (DFO database).</p></td></tr><tr><td>dfo_other_country</td><td>STRING</td><td><p>Secondary country of flooding (DFO database).</p></td></tr><tr><td>dfo_displaced</td><td>INT</td><td><p>Estimated total number of people left homeless or evacuated after a\\nflood event (DFO database).</p></td></tr><tr><td>dfo_main_cause</td><td>STRING</td><td><p>The main cause of a flood event in the DFO database. Not normalized.</p></td></tr><tr><td>dfo_severity</td><td>DOUBLE</td><td><p>Severity of a flood event (DFO database):</p><ul><li>1 - large flood events, significant damage to structure or agriculture,\\nfatalities, and/or 5-15 year reported interval since the last\\nsimilar event</li><li>1.5 - very large events: &gt;15 year but &lt;100 year recurrence interval</li><li>2 - extreme events: recurrence interval &gt;100 years)</li></ul></td></tr><tr><td>dfo_dead</td><td>INT</td><td><p>Estimated fatalities due to a flood event (DFO database).</p></td></tr><tr><td>dfo_validation_type</td><td>STRING</td><td><p>Primary source of flood event confirmation (DFO database). Not normalized.</p></td></tr><tr><td>glide_index</td><td>STRING</td><td><p><a href=\"https://glidenumber.net/glide/public/about.jsp\">GLobal IDEntifier Number</a>.</p></td></tr><tr><td>gfd_country_code</td><td>STRING</td><td><p>Comma-separated list of two-letter FIPS country codes for countries\\nintersecting with the watershed used as the area of interest\\nin the water detection algorithm.</p></td></tr><tr><td>gfd_country_name</td><td>STRING</td><td><p>Country names (in a list) for countries intersecting with the watershed\\nused as the area of interest in the water detection algorithm.</p></td></tr><tr><td>composite_type</td><td>STRING</td><td><p>Number of days used for compositing in water detection algorithm.</p></td></tr><tr><td>threshold_type</td><td>STRING</td><td><p>Type of thresholds used to classify water/ non-water in water detection\\nalgorithm - &quot;otsu&quot; or &quot;standard&quot;.</p></td></tr><tr><td>threshold_b1b2</td><td>DOUBLE</td><td><p>Threshold value applied to the b2b1-ratio used in the water detection\\nalgorithm.</p></td></tr><tr><td>threshold_b7</td><td>DOUBLE</td><td><p>Threshold value applied to band 7 (SWIR) used in the water detection\\nalgorithm.</p></td></tr><tr><td>otsu_sample_res</td><td>DOUBLE</td><td><p>Spatial resolution (in m) of the reducer used to build MODIS mosaic from\\nwhich to then sample and estimate an otsu threshold (only available for flood\\nevents which used an otsu and not the default threshold).</p></td></tr><tr><td>slope_threshold</td><td>DOUBLE</td><td><p>Value used to mask steep areas from water detection algorithm to\\nminimize error from terrain shadows.</p></td></tr></table><p><b>Terms of Use</b><br><p>This work is licensed under the Creative Commons Attribution Non Commercial 4.0\\nInternational license.</p><p><b>Suggested citation(s)</b><ul><li><p>Tellman, B., J.A. Sullivan, C. Kuhn, A.J. Kettner, C.S. Doyle, G.R.\\nBrakenridge, T. Erickson, D.A. Slayback. (Accepted.)\\nSatellites observe increasing proportion of population exposed\\nto floods. Nature.\\n<a href=\"https://doi.org/10.1038/s41586-021-03695-w\">doi:10.1038/s41586-021-03695-w</a></p></li></ul><style>\\n  table.eecat {\\n  border: 1px solid black;\\n  border-collapse: collapse;\\n  font-size: 13px;\\n  }\\n  table.eecat td, tr, th {\\n  text-align: left; vertical-align: top;\\n  border: 1px solid gray; padding: 3px;\\n  }\\n  td.nobreak { white-space: nowrap; }\\n</style>',\n",
       "  'source_tags': ['c2s', 'cloudtostreet', 'dartmouth', 'dfo'],\n",
       "  'provider_url': 'http://global-flood-database.cloudtostreet.info/',\n",
       "  'title': 'Global Flood Database v1 (2000-2018)',\n",
       "  'sample': 'https://mw1.google.com/ges/dd/images/GLOBAL_FLOOD_DB_MODIS_EVENTS_V1_0_sample.png',\n",
       "  'tags': ['c2s',\n",
       "   'cloudtostreet',\n",
       "   'dartmouth',\n",
       "   'dfo',\n",
       "   'flood',\n",
       "   'gfd',\n",
       "   'inundation',\n",
       "   'surface',\n",
       "   'water'],\n",
       "  'product_tags': ['gfd', 'inundation', 'surface', 'water', 'flood'],\n",
       "  'provider': 'Cloud to Street (C2S) / Dartmouth Flood Observatory (DFO)',\n",
       "  'visualization_0_name': 'Flood duration in days',\n",
       "  'visualization_0_bands': ''},\n",
       " 'features': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test = ee.Image(gfd.filterMetadata('id', 'equals', hurricaneIsaacDartmouthId).first());\n",
    "\n",
    "collection = ee.ImageCollection(\"GLOBAL_FLOOD_DB/MODIS_EVENTS/V1\").filterDate('2000-02-17', '2018-12-10')\n",
    "\n",
    "filtered = collection.filter(ee.Filter.eq('countries', 'philippines'));\n",
    "\n",
    "collection.getInfo()\n",
    "\n",
    "filtered.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fdee424-932e-4737-8395-65d7de7ba096",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m hurricaneIsaacUsa \u001b[38;5;241m=\u001b[39m ee\u001b[38;5;241m.\u001b[39mImage(gfd\u001b[38;5;241m.\u001b[39mfilterMetadata(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequals\u001b[39m\u001b[38;5;124m'\u001b[39m, hurricaneIsaacDartmouthId)\u001b[38;5;241m.\u001b[39mfirst());\n\u001b[1;32m      3\u001b[0m flood \u001b[38;5;241m=\u001b[39m hurricaneIsaacUsa\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflooded\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m flood_test \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflood\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/carto/lib/python3.8/site-packages/pandas/core/frame.py:780\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# For data is scalar\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 780\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame constructor not properly called!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    782\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[1;32m    783\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "hurricaneIsaacUsa = ee.Image(gfd.filterMetadata('id', 'equals', hurricaneIsaacDartmouthId).first());\n",
    "\n",
    "flood = hurricaneIsaacUsa.select('flooded')\n",
    "\n",
    "flood_test = pd.DataFrame(flood)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19159904-9e00-44c0-95b5-ee06607071f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BELOW CODE DOESN'T WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ae7533d-a12e-4c03-b0fa-9f093148904a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Longitude, latitude of Philippines\n",
    "philippines_lon = 121.7740\n",
    "philippines_lat = 12.8797\n",
    "\n",
    "# Create GEE point object for Phillipines lon/lat\n",
    "philippines_poi = ee.Geometry.Point(philippines_lon, philippines_lat)\n",
    "\n",
    "# Define radius within which to grab data\n",
    "scale = 2000000   #scale in m\n",
    "\n",
    "# Load flood image collection\n",
    "flood_base = ee.ImageCollection(\"GLOBAL_FLOOD_DB/MODIS_EVENTS/V1\")\n",
    "\n",
    "# Select flooding variable\n",
    "flooding = flood_base.select('flooded')\n",
    "\n",
    "#type(flooding['flooded'])\n",
    "\n",
    "#Store precipitation around Philipines\n",
    "\n",
    "flood_philippines = flooding.getRegion(philippines_poi, scale).getInfo()\n",
    "\n",
    "flood_philippines\n",
    "\n",
    "# Turn flooding information from GEE into a Pandas DataFrame\n",
    "flood_philippines_df = pd.DataFrame(flood_philippines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d93e34f7-7141-4ffb-a877-10ac337cbbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           id\n",
      "1    longitude\n",
      "2     latitude\n",
      "3         time\n",
      "4      flooded\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Assign the first entry in the data frame to a variable called \"headers\"\n",
    "headers = flood_philippines_df.loc[0]  \n",
    "\n",
    "# Look at what's in there\n",
    "print(headers)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee9e6b22-ef2b-4f55-9331-eae8c2addec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                   id   longitude  latitude           time  \\\n",
      "0   DFO_1614_From_20000711_to_20000810  116.780987  8.983153   963273600000   \n",
      "1   DFO_1781_From_20010815_to_20011119  116.780987  8.983153   997833600000   \n",
      "2   DFO_1981_From_20020706_to_20020719  116.780987  8.983153  1025913600000   \n",
      "3   DFO_1991_From_20020715_to_20021202  116.780987  8.983153  1026691200000   \n",
      "4   DFO_1998_From_20020720_to_20020728  116.780987  8.983153  1027123200000   \n",
      "..                                 ...         ...       ...            ...   \n",
      "80  DFO_4318_From_20151212_to_20160106  116.780987  8.983153  1449878400000   \n",
      "81  DFO_4330_From_20160118_to_20160310  116.780987  8.983153  1453075200000   \n",
      "82  DFO_4485_From_20170612_to_20170614  116.780987  8.983153  1497225600000   \n",
      "83  DFO_4653_From_20180717_to_20180723  116.780987  8.983153  1531785600000   \n",
      "84  DFO_4704_From_20181124_to_20181129  116.780987  8.983153  1543017600000   \n",
      "\n",
      "0  flooded  \n",
      "0     None  \n",
      "1     None  \n",
      "2     None  \n",
      "3     None  \n",
      "4     None  \n",
      "..     ...  \n",
      "80    None  \n",
      "81    None  \n",
      "82    None  \n",
      "83    None  \n",
      "84    None  \n",
      "\n",
      "[85 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Make a new df out of the old one, but assigning the names we just retrieved as actual column headers\n",
    "philippines_df = pd.DataFrame(flood_philippines_df.values[1:], columns=headers)      \n",
    "\n",
    "# Make sure it worked\n",
    "print(philippines_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c00c550b-2ad1-481f-988c-a23d83cb7627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding datetime column with dates in ISO format\n",
    "philippines_df['datetime'] = pd.to_datetime(philippines_df['time'], unit='ms') \n",
    "\n",
    "#making sure our datetime column looks good\n",
    "#print(philippines_df) \n",
    "\n",
    "type(philippines_df['flooded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30253e61-0707-4540-9c86-9afc6df27958",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='display'></a> \n",
    "### Metadata Display and Basic Visualization\n",
    "\n",
    "Next, provide some example commands to take a quick look at what is in your dataset. We've done some things along these lines in class by now, but you should include at least one of:\n",
    "\n",
    "- Metadata display: commands to indicate a) which variables are included in the dataset and their names; b) coordinate information associated with the data variables; c) other important metadata parameters (site names, etc); and d) any important information on missing data\n",
    "- Basic visualization: a \"quick and dirty\" plot showing generally what the data look like. Depending on your dataset, this could be either a time series or a map (no fancy coordinate reference system/projection needed yet)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62354cdf-609f-487d-be51-9ea306997a69",
   "metadata": {},
   "source": [
    "<a id='usecases'></a> \n",
    "### Use Case Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b04a9-b2bb-40ed-bb8c-9c75d3494c38",
   "metadata": {},
   "source": [
    "This is the \"meat\" of the notebook, and what will take the majority of the time to present in class. This section should provide:\n",
    "1) A plain-text summary (1-2 paragraphs) of the use case example you have chosen: include the target users and audience, and potential applicability. \n",
    "\n",
    "2) Markdown and code blocks demonstrating how one walks through the desired use case example. This should be similar to the labs we've done in class: you might want to demonstrate how to isolate a particularly interesting time period, then create an image showing a feature you're interested in, for example.\n",
    "\n",
    "3) A discussion of the results and how they might be extended on further analysis. For example, if there are data quality issues which impact the results, you could discuss how these might be mitigated with additional information/analysis.\n",
    "\n",
    "Just keep in mind, you'll have roughly 20 minutes for your full presentation, and that goes surprisingly quickly! Probably 2-3 diagnostics is the most you'll be able to get through (you could try practicing with your group members to get a sense of timing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d07de0d-1e81-442a-a895-7b7fd7906385",
   "metadata": {},
   "source": [
    "<a id='binder'></a> \n",
    "### Create Binder Environment\n",
    "\n",
    "The last step is to create a Binder environment for your project, so that we don't have to spend time configuring everyone's environment each time we switch between group presentations. Instructions are below:\n",
    "\n",
    " - Assemble all of the data needed in your Github repo: Jupyter notebooks, a README file, and any datasets needed (these should be small, if included within the repo). Larger datasets should be stored on a separate server, and access codes included within the Jupyter notebook as discussed above. \n",
    " \n",
    " - Create an _environment_ file: this is a text file which contains information on the packages needed in order to execute your code. The filename should be \"environment.yml\": an example that you can use for the proper syntax is included in this template repo. To determine which packages to include, you'll probably want to start by displaying the packages loaded in your environment: you can use the command `conda list -n [environment_name]` to get a list.\n",
    " \n",
    " More information on environment files can be found here:\n",
    " https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#\n",
    "\n",
    " - Create Binder. Use http://mybinder.org to create a  URL for your notebook Binder (you will need to enter your GitHub repo URL). You can also add a Launch Binder button directly to your GitHub repo, by including the following in your README.md:\n",
    "\n",
    "```\n",
    "launch with myBinder\n",
    "[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/<path to your repo>)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62c774b-8a7c-4f47-9c07-7f9823c48473",
   "metadata": {},
   "source": [
    "<a id='references'></a> \n",
    "### References\n",
    "\n",
    "List relevant references. Here are some additional resources on creating professional, shareable notebooks you may find useful:\n",
    "\n",
    "1. Notebook sharing guidelines from reproducible-science-curriculum: https://reproducible-science-curriculum.github.io/publication-RR-Jupyter/\n",
    "2. Guide for developing shareable notebooks by Kevin Coakley, SDSC: https://github.com/kevincoakley/sharing-jupyter-notebooks/raw/master/Jupyter-Notebooks-Sharing-Recommendations.pdf\n",
    "3. Guide for sharing notebooks by Andrea Zonca, SDSC: https://zonca.dev/2020/09/how-to-share-jupyter-notebooks.html\n",
    "4. Jupyter Notebook Best Practices: https://towardsdatascience.com/jupyter-notebook-best-practices-f430a6ba8c69\n",
    "5. Introduction to Jupyter templates nbextension: https://towardsdatascience.com/stop-copy-pasting-notebooks-embrace-jupyter-templates-6bd7b6c00b94  \n",
    "    5.1. Table of Contents (Toc2) readthedocs: https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/toc2/README.html  \n",
    "    5.2. Steps to install toc2: https://stackoverflow.com/questions/23435723/installing-ipython-notebook-table-of-contents\n",
    "6. Rule A, Birmingham A, Zuniga C, Altintas I, Huang SC, et al. (2019) Ten simple rules for writing and sharing computational analyses in Jupyter Notebooks. PLOS Computational Biology 15(7): e1007007. https://doi.org/10.1371/journal.pcbi.1007007. Supplementary materials: example notebooks (https://github.com/jupyter-guide/ten-rules-jupyter) and tutorial (https://github.com/ISMB-ECCB-2019-Tutorial-AM4/reproducible-computational-workflows)\n",
    "7. Languages supported by Jupyter kernels: https://github.com/jupyter/jupyter/wiki/Jupyter-kernels\n",
    "8. EarthCube notebooks presented at EC Annual Meeting 2020: https://www.earthcube.org/notebooks\n",
    "9. Manage your Python Virtual Environment with Conda: https://towardsdatascience.com/manage-your-python-virtual-environment-with-conda-a0d2934d5195\n",
    "10. Venv - Creation of Virtual Environments: https://docs.python.org/3/library/venv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f10df5-100c-4f4a-a1c3-bd417b524a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carto",
   "language": "python",
   "name": "carto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
